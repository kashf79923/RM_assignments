{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Methods <br>UHH - Knowledge Technology Research Group - WiSe 2024/2025\n",
    "## Assignment #2 - Empirical Studies & EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Group: \n",
    "### Names of members: \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "Please answer the questions below. Copy this notebook and enter your answers underneath each task description, inserting cells as needed. You may use a combination of [python 3](https://www.python.org), [markdown](http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html), and [LaTeX](https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd) to formulate your responses. In order to successfully complete the assignment, you will need the lecture material provided in the [RM moodle course](https://lernen.min.uni-hamburg.de/course/view.php?id=4709), especially L02 & L03.\n",
    "\n",
    "**Make sure to use only a copy of this notebook for your answers instead of a new/blank notebook.** \n",
    "\n",
    "### Grading Criteria:\n",
    "\n",
    "In order to successfully pass this assignment, you will need **at least a total of 70 points out of 100 points**, and every task has to be tackled.\n",
    "\n",
    "### Submission:\n",
    "\n",
    "Please upload the following two files **until Tuesday, November 5, 2024, 20:00 CET (Germany)** together in a .zip archive in moodle:\n",
    "1. a (single) copy of this jupyter notebook containing your answers for all tasks (file extension: .ipynb)\n",
    "2. an [exported PDF document](https://jupyterlab.readthedocs.io/en/stable/user/export.html) of the jupyter notebook (file extension: .pdf)\n",
    "\n",
    "### Presentation:\n",
    "\n",
    "Make sure that each (!) group member takes part in solving this assignment and is prepared to answer questions and/or present solutions from your submitted notebook during our assignment revision meeting scheduled for **Wednesday, November 13, 2024, 10:00 - 13:00 CET (Germany)**.\n",
    "\n",
    "### File Naming:\n",
    "\n",
    "Add the group letter to the file name prior to submission. For example, if your group letter is \"A\" (see group selection in moodle), you would use the following filename: \n",
    "1. RM_A02_Group_A.ipynb\n",
    "2. RM_A02_Group_A.pdf\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 **[10 points] Data Scales**\n",
    "\n",
    "1. For each of the features in the CRU dataset (e.g., precipitation), identify all scales of data whose definition is valid for all entries in the columns that belong to that feature. Create a table using python code that contains all features as rows, data scales as columns, and binary table entries indicating whether the feature values (i.e., column entries in the database) correspond to the data scale or not.\n",
    "2. For each of the features, briefly explain to which of the errors mentioned in the lecture this feature is prone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categorial</th>\n",
       "      <th>Ordinal</th>\n",
       "      <th>Interval</th>\n",
       "      <th>Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Temperature</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wet days</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precipitation</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Categorial Ordinal Interval Ratio\n",
       "Temperature            0       0        1     0\n",
       "Wet days               0       0        0     1\n",
       "Precipitation          0       0        0     1"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"data/CRU_data.csv\", sep = \";\")\n",
    "# df\n",
    "\n",
    "\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# num_drop_cols = 2087\n",
    "\n",
    "# df_dropped_dynamic = df.iloc[:, :-num_drop_cols]\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Categorial': ['0', '0', '0'],\n",
    "    'Ordinal': ['0', '0', '0'],\n",
    "    'Interval': ['1', '0', '0'],\n",
    "    'Ratio': ['0', '1', '1']\n",
    "}\n",
    "df = pd.DataFrame(data, index=[\"Temperature\", \"Wet days\", \"Precipitation\"])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.2\n",
    "\n",
    "* Temperature: Interval Data\n",
    "  * There is no true zero for Celcius degree temperature so it cannot be Ratio scale. Example: 0°C is defined as the freezing point of water. There is still temperature (molecules movement) at 0°C.\n",
    "  * The range between Celcius degree has its meaning so it is Interval. Example: 20°C feels warmer than 10°C, 30°C is warmer than 20°C, but  20°C is not twice as much as 10°C.\n",
    "* Wet days: Ratio data\n",
    "  * Wet days are in Ratio scale because there is a true zero point.\n",
    "  * Example: 0 wet day means there is no wet days during the month.\n",
    "* Precipitation: Ratio data\n",
    "  * Precipitation is in Ratio scale because there is a true zero point.\n",
    "  * Precipitation has measurable unit (assuming it is in Millimeters)\n",
    "  * Example: 0 precipitation means there is no rain during the month.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 **[10 points] Types of Experiments**\n",
    "\n",
    "Different types of studies and experiments were discussed in the lecture. With respect to climate data, state whether it is possible to conduct the following experiments given below. Briefly explain your reasoning and give an example for each of the four types.\n",
    "\n",
    "1. Exploratory study\n",
    "2. Assessment study\n",
    "3. Observation experiments\n",
    "4. Manipulation experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "#### 1. **Exploratory Study**\n",
    "\n",
    "- **Suitable Data**: Qualitative data such as interviews, focus groups, open-ended survey responses, and observations. Quantitative data can also be used, particularly if it's descriptive statistics or secondary data that provides context.\n",
    "- **Purpose**: To identify patterns, generate hypotheses, or understand a phenomenon without a specific outcome in mind.\n",
    "- **Conclusion**: Exploratory Study can be conducted in the context of Climate. The climate data can displays the weather features clearly. Such data also indicates some patterns, which helps with understanding the climate.\n",
    "#### 2. **Assessment Study**\n",
    "\n",
    "- **Suitable Data**: Quantitative data, such as surveys with closed-ended questions, standardized tests, or performance metrics. Qualitative data can complement this, providing deeper insights through interviews or case studies.\n",
    "- **Purpose**: To evaluate the effectiveness of a program, intervention, or policy by measuring outcomes against set criteria.\n",
    "- **Conclusion**: Assessment Study can be conducted in the context of Climate. Climate's features are measurable so I believe it is possible to derive your assessments out of the data. For example, you could assess the climate change impacts by measuring and assessing some climate's feature data.\n",
    "\n",
    "#### 3. **Observation Experiments**\n",
    "\n",
    "- **Suitable Data**: Qualitative data from direct observations, field notes, video recordings, and behavioral checklists. Quantitative data may also be collected through structured observation methods, such as tallying specific behaviors.\n",
    "- **Purpose**: To gather data in a natural setting without manipulating variables, aiming to understand behavior in context.\n",
    "- **Conclusion**: Observation experiments can also be conducted with climate data. We can easily observe the climate's changes and behaviors without interfering. Both qualitative data and quantitative data can be used to test your hypothesis through observation.\n",
    "\n",
    "#### 4. **Manipulation Experiments**\n",
    "\n",
    "- **Suitable Data**: Primarily quantitative data from controlled experiments, including measurements of dependent variables, pre- and post-tests, and surveys. Randomization helps in minimizing biases.\n",
    "- **Purpose**: To establish cause-and-effect relationships by manipulating one or more independent variables and observing the effects on dependent variables.\n",
    "- **Conclusion**: It depends on different aspects of your hypothesis like the scale and the scope. The climate data can not be used for Manipulation Experiments in some cases. The dataset includes the measurement of weather's features like temperature and precipitation. Therefore, it is fairly hard to mimic or simulate/manipulate this climate data. For example, if you conduct Manipulation experiments to test your hypothesis relating to the effect of Winter on people's mood or mental health, it would be too complex to manipulate the climate variable because humans are complex and require a real-world setting. Observation experiment is recommended in this case. But if you do such experiments to see if a plant species could survive Germany's winter, then I believe it is do-able to some extents. For example, we can some how simulate the winter's features like temperature, precipitation and humidity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3 **[40 points] Visualization**\n",
    "\n",
    "Plot the four statistics given below using suitable python packages:\n",
    "\n",
    "1. Timeline of cumulative precipitation over the course of the year 2023. _(i)_ world-wide and _(ii)_ per country.\n",
    "2. Average precipitation per wetday per country in 2023.\n",
    "3. Climate diagram based on the average data from the last decade (2014 - 2023) for one country of your choice.<br> _Note: Include the amount of precipitation as well as min, mean, and max temperature._ <br> _Hint: Check out online how climate diagrams typically look like._\n",
    "4. Frequency distribution of mean temperatures in Germany in the timespans (i) 1904-1923 and (ii) 2004-2023. <br> _Note: Use appropriate, common bins for both diagrams._\n",
    "\n",
    "As a reminder, the following instructions will apply to **all visualization tasks** as part of the RM course: Make sure to use appropriate plot types for visualization (e.g., histogram, bar plot, scatter plot, line plot, ...) and proper axis labeling/scaling. Add a legend to each plot to facilitate the viewer's understanding. Make sure to describe/interpret the outcome of your visualization.\n",
    "\n",
    "_Hint: It might be helpful to use the [wide__to__long](https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html) function in pandas to format the data for plotting!_ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4 **[40 points] EDA**\n",
    "\n",
    "Following the Titanic example from the lecture, we want to gain first insights into multivariate EDA. We want to see if the climate warming is different between countries. For this purpose, take the following steps using python to answer the question **whether the number of warmer/colder months (compared to 50 years ago) changes between countries and whether there is a difference between decades.**\n",
    "\n",
    "For this task use the data from Pakistan and Spain starting from the year 1964.\n",
    "\n",
    "1. For each month, calculate if it was warmer or colder compared to the same month 50 years ago (e.g., you compare 01/1964 with 01/1914, then 02/1964 with 02/1914, ...).\n",
    "2. Create two contingency tables of **total number of warmer and colder months per country** (one containing the absolute counts and the second one containing row and column proportions).\n",
    "3. Create another two contingency tables of **total number of warmer and colder months per decade** (one containing the absolute counts and the second one containing row and column proportions).\n",
    "4. Plot a histogram or bar chart that shows the **total number of warmer months by country and decade**.\n",
    "   _Hint: The usage of different colors might help a lot!_\n",
    "6. Now combine the contingency tables of task 4.2 and 4.3 (see Titanic example discussed in the EDA lecture), so that you have a subdivision into countries by decade, with absolute counts and row/column proportions.\n",
    "7. Calculate the expected frequencies $f_e$ for each conjunct event in the contingency table from task 4.5 and create a copy of the table from task 4.5 containing the $f_e$ values.\n",
    "8. Calculate $\\chi²_{Pakistan}$ and $\\chi²_{Spain}$ and interpret.\n",
    "9. What does a small $\\chi²$ value mean? What if it's zero? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
